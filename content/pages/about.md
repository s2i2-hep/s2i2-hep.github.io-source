Title: DIANA Overview
date: 2015-05-10 10:53
slug: about.html
Authors: Kyle Cranmer
Summary: Summary of the DIANA Project


Advanced software plays a fundamental role in large 
scientific projects. The primary goal of DIANA/HEP is to develop 
state-of-the-art tools for
experiments which acquire, reduce, and analyze petabytes of data.
Improving performance, interoperability, and collaborative tools
through modifications and additions to ROOT and other packages broadly
used by the
community will allow users to more fully exploit the data being
acquired at CERN's Large Hadron Collider (LHC) and other facilities.
As part of the NSF's [Software Infrastructure for Sustained Innovation (SI2)](http://www.nsf.gov/funding/pgm_summ.jsp?pims_id=504817) program, DIANA is concerned with the overarching goal of transforming innovations in research and education into sustained software resources that are an integral part of the cyberinfrastructure.

<!--
### Focus Areas

   *  increase the CPU and IO performance needed to reduce
the iteration time so crucial to exploring new ideas, 

   *  develop
software to effectively exploit emerging many- and multi-core
hardware,

   * establish infrastructure for a higher-level of
collaborative analysis, building on the successful patterns used
for the Higgs boson discovery and enabling a deeper communication
between the theoretical community and the experimental community,

   * streamline efforts associated to reproducibility, analysis preservation, and data preservation by making these native concepts in the tools, 

   * promote the concept of software as a research product,

   *  improve the interoperability of HEP tools with the larger scientific software
ecosystem, incorporating best practices and algorithms from other disciplines into HEP, and

   *  provide training for students in these techniques.
-->

<!--
Advanced software plays a fundamental role in large 
scientific projects. The primary goal of DIANA/HEP (Data Intensive ANAlysis
for High Energy Physics) is to develop state-of-the-art tools for
experiments which acquire, reduce, and analyze petabytes of data.
Improving performance, interoperability, and collaborative tools
through modifications and additions to packages broadly used by the
community will allow users to more fully exploit the data being
acquired at CERN's Large Hadron Collider (LHC) and other facilities.
These experiments are addressing questions at the heart of physics
-- what are the underlying constituents of matter and how do they
interact? With the discovery of the Higgs boson in 2012, the Standard
Model of particle physics is complete. It provides an excellent
description of known particles and forces. However, the most
interesting questions remain open, for example: What is the dark matter 
which pervades the universe? Does space-time have additional symmetries
or extend beyond the 3 spatial dimensions we know? What is the
mechanism stabilizing the Higgs boson mass from enormous quantum
corrections? 


The next generation of experiments will collect exabyte-scale data samples 
to provide answers to these and many other questions. Analyzing this data will 
require new and better tools. DIANA will provide the CPU and IO performance needed to reduce
the iteration time so crucial to explore new ideas. We will develop
software to effectively exploit emerging many- and multi-core
hardware. We will establish infrastructure for a higher-level of
collaborative analysis, building on the successful patterns used
for the Higgs boson discovery and enabling a deeper communication
between the theoretical community and the experimental community.
DIANA's products will sit in the ROOT framework, already used by
our community of more than 10,000 particle and nuclear physicists.
By improving interoperability with the larger scientific software
ecosystem, DIANA will also incorporate best practices and algorithms
from other disciplines into HEP.  We will provide training for students
in these techniques.
Similarly, we will make our computing
insights, tools, and novel ideas related to collaborative analysis,
standards for data preservation, and best practices for treating
software as a research product available to the larger scientific
community.
-->

### Project Team

  * [Peter Elmer](http://www.princeton.edu/physics/people/display_person.xml?netid=gelmer&display=Research%20Staff) (Lead PI) - Princeton University, Department of Physics

  * [Michael D. Sokoloff](http://www.artsci.uc.edu/departments/physics/fac_staff.html?eid=sokoloff&thecomp=uceprof) (PI) - University of Cincinnati, Department of Physics

  * [Mark Neubauer](https://physics.illinois.edu/people/profile.asp?msn) (PI) - University of Illinois at Urbana-Champaign, Department of Physics


  * [Nan Niu](http://homepages.uc.edu/~niunn/) (Senior Personnel) - University of Cincinnati, Department of EECS

### Acknowledgement

This project is supported by [National Science Foundation](http://nsf.gov) grants ACI-1450310, ACI-1450319, ACI-1450323, and ACI-1450377. Any opinions, findings, conclusions or recommendations expressed in this material are those of the developers and do not necessarily reflect the views of the National Science Foundation.



